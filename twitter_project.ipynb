{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3425490363.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [10]\u001b[1;36m\u001b[0m\n\u001b[1;33m    conda install matplotlib\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Remember to install in virtual environment\n",
    "!pip3 install sqlalchemy\n",
    "!pip3 install transformers\n",
    "!pip3 install pymysql\n",
    "!pip3 install TensorFlow\n",
    "!pip3 install snscrape\n",
    "!pip3 install pandas\n",
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sntwitter for get tweets\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "#import pandasd for making a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# query format and limit\n",
    "query = \" #Vaccination until:2020-04-01 since:2020-01-01\" # search by keywords\n",
    "#query = \"(from:joebiden) until:2022-08-31 since:2021-01-01\" # search by user\n",
    "tweets = [] # tweets (var) = list \n",
    "limit = 10000 # tweets limit i wanna get\n",
    "\n",
    "# To get tweet by using sntwitter\n",
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    \n",
    "      #print(vars(tweet)) # Raw data from tweets\n",
    "      #break \n",
    "    if len(tweets) == limit: # Get tweet till it reached the limit set above\n",
    "        break # Condition = True jau end loop\n",
    "    else: # Get all tweet and put into a list \n",
    "        tweets.append([tweet.date, tweet.url, tweet.user.username, tweet.sourceLabel, tweet.user.location, tweet.content, tweet.likeCount, tweet.retweetCount,  tweet.quoteCount, tweet.replyCount])\n",
    "        #tweets.append([tweet.date, tweet.username, tweet.content])\n",
    "        \n",
    "# Make the list into a dataframe by using pandas\n",
    "df = pd.DataFrame(tweets, columns=['Date', 'TweetURL','User', 'Source', 'Location', 'Tweet', 'Likes_Count','Retweet_Count', 'Quote_Count', 'Reply_Count'])\n",
    "#df = pd.DataFrame(tweets, columns=['Date', 'User', 'Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5279 entries, 0 to 5278\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   Date           5279 non-null   datetime64[ns, UTC]\n",
      " 1   TweetURL       5279 non-null   object             \n",
      " 2   User           5279 non-null   object             \n",
      " 3   Source         5279 non-null   object             \n",
      " 4   Location       5279 non-null   object             \n",
      " 5   Tweet          5279 non-null   object             \n",
      " 6   Likes_Count    5279 non-null   int64              \n",
      " 7   Retweet_Count  5279 non-null   int64              \n",
      " 8   Quote_Count    5279 non-null   int64              \n",
      " 9   Reply_Count    5279 non-null   int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(4), object(5)\n",
      "memory usage: 412.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5279"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inserting Pandas DataFrames into a Database Using the to_sql() Function\n",
    "# import the module\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# create sqlalchemy engine\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@localhost/{db}\"\n",
    "                       .format(user=\"root\",\n",
    "                               pw=\"aA25059246\",\n",
    "                               db=\"20221003\"))\n",
    "\n",
    "# Insert whole DataFrame into MySQL\n",
    "df.to_sql('tweets_3months', con = engine, if_exists = 'append', chunksize = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>TweetURL</th>\n",
       "      <th>User</th>\n",
       "      <th>Source</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Likes_Count</th>\n",
       "      <th>Retweet_Count</th>\n",
       "      <th>Quote_Count</th>\n",
       "      <th>Reply_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-31 23:56:57</td>\n",
       "      <td>https://twitter.com/JanaianaUchoa/status/12451...</td>\n",
       "      <td>JanaianaUchoa</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>Fortaleza, Brasil</td>\n",
       "      <td>Meu presidente. Sempre atento a necessidade do...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-31 23:54:01</td>\n",
       "      <td>https://twitter.com/AlfredoMorabia/status/1245...</td>\n",
       "      <td>AlfredoMorabia</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>Queens College, New York City</td>\n",
       "      <td>#SooninAJPH \"The School Vaccination Assessment...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-03-31 23:16:05</td>\n",
       "      <td>https://twitter.com/picphysicians/status/12451...</td>\n",
       "      <td>picphysicians</td>\n",
       "      <td>Agorapulse app</td>\n",
       "      <td>Newport Beach, CA</td>\n",
       "      <td>Did you know that the primary statistician for...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-03-31 23:00:19</td>\n",
       "      <td>https://twitter.com/MicrobesInfo/status/124512...</td>\n",
       "      <td>MicrobesInfo</td>\n",
       "      <td>Buffer</td>\n",
       "      <td>Earth</td>\n",
       "      <td>A #coronavirus #vaccine in 18 months is risky ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-03-31 22:40:49</td>\n",
       "      <td>https://twitter.com/aliya_Hshah/status/1245118...</td>\n",
       "      <td>aliya_Hshah</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>City of London, London</td>\n",
       "      <td>#USA just signed a $450 million #coronavirus #...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                Date  \\\n",
       "0      0 2020-03-31 23:56:57   \n",
       "1      1 2020-03-31 23:54:01   \n",
       "2      2 2020-03-31 23:16:05   \n",
       "3      3 2020-03-31 23:00:19   \n",
       "4      4 2020-03-31 22:40:49   \n",
       "\n",
       "                                            TweetURL            User  \\\n",
       "0  https://twitter.com/JanaianaUchoa/status/12451...   JanaianaUchoa   \n",
       "1  https://twitter.com/AlfredoMorabia/status/1245...  AlfredoMorabia   \n",
       "2  https://twitter.com/picphysicians/status/12451...   picphysicians   \n",
       "3  https://twitter.com/MicrobesInfo/status/124512...    MicrobesInfo   \n",
       "4  https://twitter.com/aliya_Hshah/status/1245118...     aliya_Hshah   \n",
       "\n",
       "                Source                       Location  \\\n",
       "0            Instagram              Fortaleza, Brasil   \n",
       "1               Buffer  Queens College, New York City   \n",
       "2       Agorapulse app              Newport Beach, CA   \n",
       "3               Buffer                          Earth   \n",
       "4  Twitter for Android         City of London, London   \n",
       "\n",
       "                                               Tweet  Likes_Count  \\\n",
       "0  Meu presidente. Sempre atento a necessidade do...            0   \n",
       "1  #SooninAJPH \"The School Vaccination Assessment...            2   \n",
       "2  Did you know that the primary statistician for...            6   \n",
       "3  A #coronavirus #vaccine in 18 months is risky ...            0   \n",
       "4  #USA just signed a $450 million #coronavirus #...            0   \n",
       "\n",
       "   Retweet_Count  Quote_Count  Reply_Count  \n",
       "0              0            0            0  \n",
       "1              1            0            0  \n",
       "2              1            0            0  \n",
       "3              0            0            0  \n",
       "4              0            0            0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'SELECT * FROM `tweets_3months`'\n",
    "query_df = pd.read_sql_query(query, engine) \n",
    "query_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.16k/1.16k [00:00<00:00, 1.17MB/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.roberta.modeling_tf_roberta because of the following error (look up to see its traceback):\ncannot import name 'dtensor' from 'tensorflow.compat.v2.experimental' (d:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\experimental\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\transformers\\utils\\import_utils.py:1031\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1031\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[0;32m   1032\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations_tf\u001b[39;00m \u001b[39mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_tf_outputs\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     TFBaseModelOutputWithPastAndCrossAttentions,\n\u001b[0;32m     28\u001b[0m     TFBaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     TFTokenClassifierOutput,\n\u001b[0;32m     35\u001b[0m )\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\transformers\\activations_tf.py:107\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mactivations\u001b[39m.\u001b[39mgelu(x, approximate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 107\u001b[0m gelu \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mactivations\u001b[39m.\u001b[39mgelu\n\u001b[0;32m    108\u001b[0m gelu_new \u001b[39m=\u001b[39m approximate_gelu_wrap\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:62\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, item):\n\u001b[1;32m---> 62\u001b[0m   module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load()\n\u001b[0;32m     63\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(module, item)\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:45\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[0;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_module_globals[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_name] \u001b[39m=\u001b[39m module\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\keras\\__init__.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\keras\\distribute\\__init__.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Keras' Distribution Strategy library.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistribute\u001b[39;00m \u001b[39mimport\u001b[39;00m sidecar_evaluator\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\keras\\distribute\\sidecar_evaluator.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecation\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizer_experimental\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     optimizer \u001b[39mas\u001b[39;00m optimizer_experimental,\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf_export\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_export\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\keras\\optimizers\\__init__.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m adadelta \u001b[39mas\u001b[39;00m adadelta_legacy\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m adagrad \u001b[39mas\u001b[39;00m adagrad_legacy\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\keras\\optimizers\\legacy\\adadelta.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Legacy Adadelta optimizer implementation.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizer_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m adadelta\n\u001b[0;32m     19\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adadelta.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend_config\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizer_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizer_v2\n\u001b[0;32m     23\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m initializers\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer_utils\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\keras\\initializers\\__init__.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minitializers\u001b[39;00m \u001b[39mimport\u001b[39;00m initializers_v1\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minitializers\u001b[39;00m \u001b[39mimport\u001b[39;00m initializers_v2\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m generic_utils\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:23\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[0;32m     25\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\keras\\dtensor\\__init__.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mif\u001b[39;00m _DTENSOR_API_ENABLED:\n\u001b[1;32m---> 22\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m \u001b[39mimport\u001b[39;00m dtensor \u001b[39mas\u001b[39;00m dtensor_api\n\u001b[0;32m     23\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39m# Leave it with a placeholder, so that the import line from other python\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[39m# file will not break.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'dtensor' from 'tensorflow.compat.v2.experimental' (d:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\experimental\\__init__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\brian\\Downloads\\twitter_project.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brian/Downloads/twitter_project.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brian/Downloads/twitter_project.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# # Set up the inference pipeline using a model from the ðŸ¤— Hub\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/brian/Downloads/twitter_project.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m sentiment_analysis \u001b[39m=\u001b[39m pipeline(model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfiniteautomata/bertweet-base-sentiment-analysis\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brian/Downloads/twitter_project.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m query_df\u001b[39m.\u001b[39minsert(\u001b[39m11\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msentiment\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brian/Downloads/twitter_project.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m query_df\u001b[39m.\u001b[39minfo()\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\transformers\\pipelines\\__init__.py:702\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[39m# Infer the framework from the model\u001b[39;00m\n\u001b[0;32m    699\u001b[0m \u001b[39m# Forced if framework already defined, inferred if it's None\u001b[39;00m\n\u001b[0;32m    700\u001b[0m \u001b[39m# Will load the correct model if possible\u001b[39;00m\n\u001b[0;32m    701\u001b[0m model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m--> 702\u001b[0m framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    703\u001b[0m     model,\n\u001b[0;32m    704\u001b[0m     model_classes\u001b[39m=\u001b[39mmodel_classes,\n\u001b[0;32m    705\u001b[0m     config\u001b[39m=\u001b[39mconfig,\n\u001b[0;32m    706\u001b[0m     framework\u001b[39m=\u001b[39mframework,\n\u001b[0;32m    707\u001b[0m     task\u001b[39m=\u001b[39mtask,\n\u001b[0;32m    708\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs,\n\u001b[0;32m    709\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    710\u001b[0m )\n\u001b[0;32m    712\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    713\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\transformers\\pipelines\\base.py:233\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m         classes\u001b[39m.\u001b[39mappend(_class)\n\u001b[0;32m    232\u001b[0m \u001b[39mif\u001b[39;00m look_tf:\n\u001b[1;32m--> 233\u001b[0m     _class \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(transformers_module, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTF\u001b[39;49m\u001b[39m{\u001b[39;49;00marchitecture\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m _class \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m         classes\u001b[39m.\u001b[39mappend(_class)\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\transformers\\utils\\import_utils.py:1022\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m   1021\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module[name])\n\u001b[1;32m-> 1022\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(module, name)\n\u001b[0;32m   1023\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1024\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\transformers\\utils\\import_utils.py:1021\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(name)\n\u001b[0;32m   1020\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m-> 1021\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_class_to_module[name])\n\u001b[0;32m   1022\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1023\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\transformers\\utils\\import_utils.py:1033\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1031\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m module_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m   1032\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1033\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1034\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1035\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1036\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.roberta.modeling_tf_roberta because of the following error (look up to see its traceback):\ncannot import name 'dtensor' from 'tensorflow.compat.v2.experimental' (d:\\Users\\brian\\anaconda3\\envs\\WebScrape\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\experimental\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# # Set up the inference pipeline using a model from the ðŸ¤— Hub\n",
    "sentiment_analysis = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "query_df.insert(11,'sentiment','')\n",
    "query_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('WebScrape')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c310a90bb8dc82b992fabd38c35429f35e1bcc6ba50b5d59175a489d88019ba5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
